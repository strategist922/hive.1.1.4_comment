PREHOOK: query: CREATE TABLE dest1(c1 INT, c2 STRING) STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
POSTHOOK: query: CREATE TABLE dest1(c1 INT, c2 STRING) STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@dest1
PREHOOK: query: explain
FROM src JOIN srcpart ON src.key = srcpart.key AND srcpart.ds = '2008-04-08' and src.key > 100
INSERT OVERWRITE TABLE dest1 SELECT src.key, srcpart.value
PREHOOK: type: QUERY
POSTHOOK: query: explain
FROM src JOIN srcpart ON src.key = srcpart.key AND srcpart.ds = '2008-04-08' and src.key > 100
INSERT OVERWRITE TABLE dest1 SELECT src.key, srcpart.value
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF src) (TOK_TABREF srcpart) (and (AND (= (. (TOK_TABLE_OR_COL src) key) (. (TOK_TABLE_OR_COL srcpart) key)) (= (. (TOK_TABLE_OR_COL srcpart) ds) '2008-04-08')) (> (. (TOK_TABLE_OR_COL src) key) 100)))) (TOK_INSERT (TOK_DESTINATION (TOK_TAB dest1)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL src) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL srcpart) value)))))

STAGE DEPENDENCIES:
  Stage-5 is a root stage , consists of Stage-6, Stage-7, Stage-1
  Stage-6 has a backup stage: Stage-1
  Stage-3 depends on stages: Stage-6
  Stage-0 depends on stages: Stage-1, Stage-3, Stage-4
  Stage-7 has a backup stage: Stage-1
  Stage-4 depends on stages: Stage-7
  Stage-1

STAGE PLANS:
  Stage: Stage-5
    Conditional Operator

  Stage: Stage-6
    Map Reduce Local Work
      Alias -> Map Local Tables:
        srcpart 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        srcpart 
          TableScan
            alias: srcpart
            Filter Operator
              predicate:
                  expr: (ds = '2008-04-08')
                  type: boolean
              HashTable Sink Operator
                condition expressions:
                  0 {key}
                  1 {value}
                handleSkewJoin: false
                keys:
                  0 [Column[key]]
                  1 [Column[key]]
                Position of Big Table: 0

  Stage: Stage-3
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            Filter Operator
              predicate:
                  expr: (key > 100)
                  type: boolean
              Filter Operator
                predicate:
                    expr: (key > 100)
                    type: boolean
                Map Join Operator
                  condition map:
                       Inner Join 0 to 1
                  condition expressions:
                    0 {key}
                    1 {value}
                  handleSkewJoin: false
                  keys:
                    0 [Column[key]]
                    1 [Column[key]]
                  outputColumnNames: _col0, _col3
                  Position of Big Table: 0
                  Select Operator
                    expressions:
                          expr: _col0
                          type: string
                          expr: _col3
                          type: string
                    outputColumnNames: _col0, _col1
                    Select Operator
                      expressions:
                            expr: UDFToInteger(_col0)
                            type: int
                            expr: _col1
                            type: string
                      outputColumnNames: _col0, _col1
                      File Output Operator
                        compressed: false
                        GlobalTableId: 1
                        table:
                            input format: org.apache.hadoop.mapred.TextInputFormat
                            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                            name: dest1
      Local Work:
        Map Reduce Local Work

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: dest1

  Stage: Stage-7
    Map Reduce Local Work
      Alias -> Map Local Tables:
        src 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        src 
          TableScan
            alias: src
            Filter Operator
              predicate:
                  expr: (key > 100)
                  type: boolean
              Filter Operator
                predicate:
                    expr: (key > 100)
                    type: boolean
                HashTable Sink Operator
                  condition expressions:
                    0 {key}
                    1 {value}
                  handleSkewJoin: false
                  keys:
                    0 [Column[key]]
                    1 [Column[key]]
                  Position of Big Table: 1

  Stage: Stage-4
    Map Reduce
      Alias -> Map Operator Tree:
        srcpart 
          TableScan
            alias: srcpart
            Filter Operator
              predicate:
                  expr: (ds = '2008-04-08')
                  type: boolean
              Map Join Operator
                condition map:
                     Inner Join 0 to 1
                condition expressions:
                  0 {key}
                  1 {value}
                handleSkewJoin: false
                keys:
                  0 [Column[key]]
                  1 [Column[key]]
                outputColumnNames: _col0, _col3
                Position of Big Table: 1
                Select Operator
                  expressions:
                        expr: _col0
                        type: string
                        expr: _col3
                        type: string
                  outputColumnNames: _col0, _col1
                  Select Operator
                    expressions:
                          expr: UDFToInteger(_col0)
                          type: int
                          expr: _col1
                          type: string
                    outputColumnNames: _col0, _col1
                    File Output Operator
                      compressed: false
                      GlobalTableId: 1
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          name: dest1
      Local Work:
        Map Reduce Local Work

  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            Filter Operator
              predicate:
                  expr: (key > 100)
                  type: boolean
              Filter Operator
                predicate:
                    expr: (key > 100)
                    type: boolean
                Reduce Output Operator
                  key expressions:
                        expr: key
                        type: string
                  sort order: +
                  Map-reduce partition columns:
                        expr: key
                        type: string
                  tag: 0
                  value expressions:
                        expr: key
                        type: string
        srcpart 
          TableScan
            alias: srcpart
            Filter Operator
              predicate:
                  expr: (ds = '2008-04-08')
                  type: boolean
              Reduce Output Operator
                key expressions:
                      expr: key
                      type: string
                sort order: +
                Map-reduce partition columns:
                      expr: key
                      type: string
                tag: 1
                value expressions:
                      expr: value
                      type: string
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0}
            1 {VALUE._col1}
          handleSkewJoin: false
          outputColumnNames: _col0, _col3
          Select Operator
            expressions:
                  expr: _col0
                  type: string
                  expr: _col3
                  type: string
            outputColumnNames: _col0, _col1
            Select Operator
              expressions:
                    expr: UDFToInteger(_col0)
                    type: int
                    expr: _col1
                    type: string
              outputColumnNames: _col0, _col1
              File Output Operator
                compressed: false
                GlobalTableId: 1
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    name: dest1


PREHOOK: query: FROM src JOIN srcpart ON src.key = srcpart.key AND srcpart.ds = '2008-04-08' and src.key > 100
INSERT OVERWRITE TABLE dest1 SELECT src.key, srcpart.value
PREHOOK: type: QUERY
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
PREHOOK: Input: default@src
PREHOOK: Output: default@dest1
POSTHOOK: query: FROM src JOIN srcpart ON src.key = srcpart.key AND srcpart.ds = '2008-04-08' and src.key > 100
INSERT OVERWRITE TABLE dest1 SELECT src.key, srcpart.value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
POSTHOOK: Input: default@src
POSTHOOK: Output: default@dest1
POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: dest1.c2 SIMPLE [(srcpart)srcpart.FieldSchema(name:hr, type:string, comment:null), ]
PREHOOK: query: SELECT sum(hash(dest1.c1,dest1.c2)) FROM dest1
PREHOOK: type: QUERY
PREHOOK: Input: default@dest1
PREHOOK: Output: file:/home/tianzhao/taobao/t_dp_dw_hive-1.1.2-156/build/ql/scratchdir/hive_2011-10-31_05-31-25_294_3404568301517737680/-mr-10000
POSTHOOK: query: SELECT sum(hash(dest1.c1,dest1.c2)) FROM dest1
POSTHOOK: type: QUERY
POSTHOOK: Input: default@dest1
POSTHOOK: Output: file:/home/tianzhao/taobao/t_dp_dw_hive-1.1.2-156/build/ql/scratchdir/hive_2011-10-31_05-31-25_294_3404568301517737680/-mr-10000
POSTHOOK: Lineage: dest1.c1 EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: dest1.c2 SIMPLE [(srcpart)srcpart.FieldSchema(name:hr, type:string, comment:null), ]
404554174174
