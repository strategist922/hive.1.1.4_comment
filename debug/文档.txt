1，map输入时候。在MapOperator中 把row反序列化

TextWritable -->通过LazySimpleSerDe --> LazyStruct 

2，在ReducerSink中 取对应的列。
无函数的列
LazyStruct --> 通过ExprNodeColumnEvaluator --> LazyString 等基础类型

函数的列：    通过ExprNodeGenericFuncEvaluator ？是在ReduceSink吗？

3，map输出时候。在ReducerSink中 把lazyObject进行序列化输出。

LazyObject --> 通过LazyBinarySerDe  --> ByteWritable (其中字节数组是自有格式)


4，explain的时候，经过编译（可能还有语义分析，优化），计划生成（各种task，内含各种operator）。执行时候只有ExplainTask（对应计划的元数据放在ExplainWork），
 在explainwork中取出task，进行遍历（最简单mapredtask，fecthtask）。各task内遍历对应的work，对work遍历desc，对desc遍历。（遍历的条件
 是有 explain 的annotation接口的方法。反射后取出返回值）
 
 （深度优先。 MapredWork   ，    JoinDesc， SelectDesc，ExprNodeColumnDesc，ExprNodeDesc，FileSinkDesc，TableDesc，FetchWork）
 
5， 中位数udaf的数据量大小受限，溢出大小危险。目前反射出现的bug修复 {null,null}
6， 分区是使用 HiveKey， 内部为hash分组。自己维护不同的hash，手动设置值。
7， 分组是通过 reducer，和operator的startgroup和endgroup 实现分组的。
8,  join过程中的分组，mr概念上是每一条记录一组，实际不是。
9， null的join是n条，空字符的join是n*n 条。消耗的时间主要在join计算上。输入输出的网络IO因素会弱点。

    考虑alter table r_rpt_cps_luna_talos_adzone set serdeproperties('serialization.null.format' = ''); 可能很好？
    
10，